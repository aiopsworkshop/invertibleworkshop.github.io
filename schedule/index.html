<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Dustin Tran, edited by Chris Cremer">
  <link rel="shortcut icon" href="../img/favicon.ico" type="image/x-icon">
  <title>Invertible Neural Nets and Normalizing Flows - Schedule</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="../css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

      <div class="hidden-xs col-sm-3 col-md-3">
      </div>

      <div class="col-xs-12 col-sm-12 col-md-9">
        <div class="row" style="margin-bottom:-10px;">
          <div class="col-xs-12 hidden-sm hidden-md hidden-lg">
            <!--
            <a href="http://nips.cc">
              <img src="/img/nips.svg" style="margin:0px -90px
              0 0; height:140px; width:250px;">
            </a>
            -->
          </div>
          <div class="hidden-xs">
            <!--
            <a href="http://nips.cc">
              <img src="/img/nips.svg" class="pull-right" style="margin:0px -90px
              0 0; height:140px; width:250px;">
            </a>
            -->
          </div>
          <h2>Workshop on Invertible Neural Nets and Normalizing Flows</h2>
<!--           <p class="lead">
            December 2, 2018<br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Le 1000 Conference Center</a><br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">1000 Rue de la Gauchetière Ouest</a><br> 
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Montréal, QC H3B 0A2, Canada</a><br>
          </p> -->
        </div>
      </div>

       <div class="col-xs-12 col-sm-3 col-md-3" id="sidebar" role="navigation">
        <hr>
        <ul class="nav nav-pills nav-stacked">
          <li><a href="../">Home</a></li>
          <li><a href=".">Schedule</a></li>
          <li><a href="../call">Call for Papers</a></li>
<!--           <li><a href="../accepted">Accepted Papers</a></li>
          <li><a href="../program">Program Committee</a></li> -->
        </ul>
        <hr>
        <ul class="nav temp">
          <li style="padding:0px 15px 5px;">Organizers</li>
            <li><a href="https://chinweihuang.com/">Chin-Wei Huang</a></li>
            <li><a href="https://mila.quebec/en/person/david-scott-krueger/">David Krueger</a></li>
            <li><a href="https://riannevdberg.github.io/">Rianne van den Berg</a></li>
            <li><a href="https://homepages.inf.ed.ac.uk/s1459647/">George Papamakarios</a></li>
            <li><a href="https://aidangomez.ca/">Aidan Gomez</a></li>
            <li><a href="https://chriscremer.bitbucket.io/">Chris Cremer</a></li>
            <li><a href="rtqichen@cs.toronto.edu">Ricky Chen</a></li>
            <li><a href="https://aaroncourville.wordpress.com/">Aaron Courville</a></li>
            <li><a href="https://danilorezende.com/">Danilo Rezende</a></li>
        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">
        <div class="row">
          <hr>
          <!--
          <p><strong>
          The workshop's recording is available on
          <a href="https://www.youtube.com/playlist?list=PLsatQfvo0v3sUhi3ijRme9MyqwLL5EOiG">
          Youtube</a>.
          </strong></p>
          -->
          <!-- <h3>Registration</h3> -->
          <!-- <h4>Chair: Francisco Ruiz</h4> -->
<!--           <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">7:30 - 8:30</td>
                <td><strong>Registration (Coffee will be served)</strong></td>
              </tr>
            </tbody>
          </table> -->
          <h3>Schedule</h3>
          <!-- <h4>Chair: Francisco Ruiz</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">&nbsp 9:30 - 10:30</td>
                <td width="18%">Eric Jang</td>
                <td>Tutorial on normalizing flows</td>
              </tr>
            </tbody>
          </table>
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">10:30 - 10:50</td>
                <td width="18%"></td>
                <td>
                Poster Spotlights
                </td>
              </tr>
              <tr>
                <td>10:50 - 11:30</td>
                <td></td>
                <td>
                Coffee break and poster session I
                </td>
              </tr>
              <tr>
                <td>11:30 - 11:50</td>
                <td>Laurent Dinh</td>
                <td>
                Invited Talk
                </td>
              </tr>
            </tbody>
          </table>
<!--           <table class="table">
            <tbody>
              <tr>
                <td width="12%">10:00 - 11:00</td>
                <td><strong>Coffee Break and Poster Session (Paper IDs 1-24)</strong></td>
              </tr>
            </tbody>
          </table>
        </div> -->

<!--         <div class="row">
          <h3>Session 2</h3> -->
          <!-- <h4>Chair: James McInerney</h4> -->
<!--           <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">11:00 - 11:20</td>
                <td width="8%">Contributed</td>
                <td>
                George Tucker: <em>Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives</em>
                <a href="/2018/schedule/Tucker2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>11:20 - 11:50</td>
                <td>Invited</td>
                <td>
                Tom Rainforth: <em>Inference Trees: Adaptive Inference with Exploration</em>
                <a href="/2018/schedule/Rainforth2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>11:50 - 12:10</td>
                <td>Contributed</td>
                <td>
                David Burt: <em>Explicit Rates of Convergence for Sparse Variational Inference in Gaussian Process Regression</em>
                <a href="/2018/schedule/Burt2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">12:10 - 13:40</td>
                <td><strong>Lunch Break (on your own)</strong></td>
              </tr>
            </tbody>
          </table>
        </div> -->

<!--         <div class="row">
          <h3>Session 3</h3> -->
          <!-- <h4>Chair: Cheng Zhang</h4> -->
<!--           <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">13:40 - 14:10</td>
                <td width="8%">Invited</td>
                <td>
                Thomas Schon: <em>Sequential Monte Carlo in the machine learning toolbox</em>
                <a href="/2018/schedule/Schon2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>14:10 - 14:30</td>
                <td>Contributed</td>
                <td>
                Badr-Eddine Chérief-Abdellatif: <em>Consistency of ELBO maximization for model selection</em>
                <a href="/2018/schedule/CheriefAbdellatif2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>14:30 - 15:00</td>
                <td>Invited</td>
                <td>
                Sebastian Nowozin: <em>Debiasing Approximate Inference</em>
                <a href="/2018/schedule/Nowozin2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">15:00 - 16:00</td>
                <td><strong>Coffee Break and Poster Session (Paper IDs 25-45)</strong></td>
              </tr>
            </tbody>
          </table>
        </div> -->

<!--         <div class="row">
          <h3>Session 4</h3> -->
          <!-- <h4>Chair: Stephan Mandt</h4> -->
<!--           <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">16:00 - 16:20</td>
                <td width="8%">Contributed</td>
                <td>
                Will Grathwohl: <em>Scalable Reversible Generative Models with Free-form Continuous Dynamics</em>
                <a href="/2018/schedule/Grathwohl2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>16:20 - 16:50</td>
                <td>Invited</td>
                <td>
                Emtiyaz Khan: <em>Fast yet Simple Natural-Gradient Descent for Variational Inference</em>
                <a href="/2018/schedule/Khan2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
              <tr>
                <td>16:50 - 17:10</td>
                <td>Contributed</td>
                <td>
                Matthew Hoffman: <em>NeuTra-lizing Bad Geometry in Hamiltonian Monte
                Carlo Using Neural Transport</em>
                <a href="/2018/schedule/Hoffman2018.pdf"
                class="btn btn-default btn-xs">Slides</a>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">17:10 - 18:00 </td>
                <td><strong>Panel</strong>
                <br>
                Alexander Alemi, David Duvenaud, Kevin Murphy, Ole Winther, Tamara Broderick
                <br>
                Moderator: Yingzhen Li
                </td>
              </tr>
            </tbody>
          </table>
        </div> -->

        
        <!-- 
        <div class="row">
          <h3>Abstracts</h3>
          <hr>
          <h4><a href="http://www.tamarabroderick.com/">Tamara Broderick</a>
          (MIT)</h4>
          <h4>Automated Scalable Bayesian Inference via Data Summarization</h4>
          <p>
          <strong>Abstract</strong>.
        	Bayesian methods are attractive for analyzing large-scale data due to
			in part to their coherent uncertainty quantification, ability to model
			complex phenomena, and ease of incorporating expert information. Many
			standard Bayesian inference algorithms are often computationally
			expensive, however, so their direct application to large datasets can
			be difficult or infeasible. Other standard algorithms sacrifice
			accuracy in the pursuit of scalability. We take a new approach.
			Namely, we leverage the insight that data often exhibit approximate
			redundancies to instead obtain a weighted subset of the data (called a
			"coreset") that is much smaller than the original dataset. We can then
			use this small coreset as input to existing Bayesian inference
			algorithms without modification. We provide theoretical guarantees on
			the size and approximation quality of the coreset. In particular, we
			show that our method provides geometric decay in posterior
			approximation error as a function of coreset size. We validate on both
			synthetic and real datasets, demonstrating that our method reduces
			posterior approximation error by orders of magnitude relative to
			uniform random subsampling.
          </p>
    	</div>
  		-->

    </div>

    <!-- <hr> -->

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="../js/main.js"></script>
</body>
</html>
